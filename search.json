[
  {
    "objectID": "posts/projects/artwork_classifier/index.html",
    "href": "posts/projects/artwork_classifier/index.html",
    "title": "Classifying Artwork Types With Fastai",
    "section": "",
    "text": "I’ve always been interested in how machine learning can apply to visual arts. In particular, computer vision feels like the most direct application to art since we can build programs to classify, modify, and even generate visuals in an artistic fashion!\nI’m by no means a deep learning aficionado but it’s exciting to tinker around with the different tools and concepts I have at my disposal. In this notebook, we will be exploring how to build out an image classification model which classifies artwork based on their different types.\nWe’ll be using the fastai framework to speed up the development process and utilize modern deep learning techniques. Along the way, I will also be covering several different concepts that I have found useful in implementing vision models. I assume some level of familiarity with machine learning concepts such as epochs and mini-batch gradient descent. And ultimately, my hope is for this notebook to become the start of projects that inspire and help other deep learning practitioners along their own journeys!"
  },
  {
    "objectID": "posts/projects/artwork_classifier/index.html#dataloader-function",
    "href": "posts/projects/artwork_classifier/index.html#dataloader-function",
    "title": "Classifying Artwork Types With Fastai",
    "section": "4.1 Dataloader Function",
    "text": "4.1 Dataloader Function\n\n\nCode\ndef get_dls(bs: int, size: int) -&gt; DataLoaders:\n    \"\"\"\n    Creates a dataloader for an image recognition task with specified batch size and image size.\n\n    # Parameters:\n    -   bs (int): Batch size.\n    -   size (int): Final size of individual images.\n\n    # Returns:\n    -   DataLoaders: A dataloader that batches our image data with specific image and batch size.\n    \"\"\"\n    db = DataBlock(\n        blocks=(ImageBlock(), CategoryBlock()),\n        get_items=get_image_files,\n        splitter=GrandparentSplitter(train_name='training_set', valid_name='validation_set'),\n        get_y=parent_label,\n        item_tfms=Resize(460),\n        batch_tfms=aug_transforms(size=size, min_scale=0.75)\n    )\n    return db.dataloaders(path, bs=bs)\n\n\nWhen we create our dataloader, we can verify that our splitter is working as we expect it to.\n\n\nCode\ndls = get_dls(64, 128)\nlen(dls.train_ds), len(dls.valid_ds)\n\n\n(7721, 856)\n\n\n\n\nCode\n# Verifying that the number of images in each directory is the same\nexts = ['.jpg', '.jpeg', '.png']\nlen([p for p in (path / 'training_set').rglob('*') if p.suffix in exts]), len([p for p in (path / 'validation_set').rglob('*') if p.suffix in exts])\n\n\n(7721, 856)\n\n\n\n\nCode\n# Show an example batch of images\ndls.show_batch()"
  },
  {
    "objectID": "posts/projects/artwork_classifier/index.html#learning-rate-finder",
    "href": "posts/projects/artwork_classifier/index.html#learning-rate-finder",
    "title": "Classifying Artwork Types With Fastai",
    "section": "5.1 Learning Rate Finder",
    "text": "5.1 Learning Rate Finder\nFor our model, we first need to select a good learning rate (LR) to start our training. Fastai implements an LR finder method Learner.lr_find based on Leslie Smith’s paper called Cyclical Learning Rates for Training Neural Networks.\nSmith describes his approach as the following:\n\nThere is a simple way to estimate reasonable minimum and maximum boundary values with one training run of the network for a few epochs. It is a “LR range test”; run your model for several epochs while letting the learning rate increase linearly between low and high LR values.\n\nEssentially, we check our training losses as we grow our learning rate to get an idea of what learning rate performs well.\nFastai takes a slightly different approach: The model is test-trained with learning rates that grow exponentially from a low LR to a higher LR across a number of mini-batches. The process continues until we find a learning rate where the loss begins to diverge and increases significantly.\nWhat this boils down to is that in the fastai version we don’t necessarily need to run for multiple epochs to get an optimal LR as we are training for a set number of mini-batches.\n\nConveniently, lr_find gives us the loss vs. LR plot and also enables us to directly extract LRs that could be optimal based off different suggestion functions. For example, I will use steep which gets the LR with the steepest slope.\n\n\nCode\nlr_steep = learn.lr_find(suggest_funcs=steep)\n\n\n\nLog plot of loss vs. learning rate"
  },
  {
    "objectID": "posts/projects/artwork_classifier/index.html#cycle-idea",
    "href": "posts/projects/artwork_classifier/index.html#cycle-idea",
    "title": "Classifying Artwork Types With Fastai",
    "section": "5.2 1cycle Idea",
    "text": "5.2 1cycle Idea\nWe can now start training our model! Using the fit_one_cycle method we are actually training our model with what is called the 1cycle policy, an idea that again comes from Leslie Smith and changes our learning rate over the course of training. I won’t be going into close detail on how the 1cycle policy is implemented in the scope of this article. At a high level, we are starting at some initial LR, linearly increasing our LR after every batch up to a maximum LR, and from the maximum LR down to some minimum LR several magnitudes lower than our initial LR.\nThe idea behind this all is to warm up our training with a low learning rate and use the high learning rate to help find minimums in our loss function that are flatter, allowing the model to generalize better. During the last segment of training, the descending learning rates help the optimizer avoid skipping over a steeper loss within the flatter areas. This process allows our model to converge faster and consequently achieve better results with lower iterations than traditional training methods. Smith calls this occurrence super-convergence.\n\n\nCode\ndef plot_example_cycle(x_min, x_max, y_min, y_max, padding):\n    values = 100\n    x = np.linspace(x_min, x_max, values + padding)\n\n    y1 = np.linspace(y_min, y_max, values // 2, endpoint=False)\n    y2 = np.linspace(y_max, y_min, values // 2, endpoint=False)\n    padded_values = np.linspace(y_min, y_min * 1e-2, padding)\n\n    y = np.concatenate((y1, y2, padded_values))\n\n    plt.plot(x, y)\n    plt.xlabel('Epochs')\n    plt.ylabel('Learning rate')\n    plt.show()\n\n\n\n\nCode\nplot_example_cycle(0, 40, 0.001, 0.01, 15)\n\n\n\n\n\nFigure 1: Example representation of a linear 1cycle learning rate schedule.\n\n\n\n\n\nWith transfer learning, our model has additional new layers that we can train for the problem we are trying to solve. At the start of training, we may not want to completely readjust the weights in the model’s previously learned layers because they account for high-level details of the image like line and shape.\nIn a pretrained model, the previous trained layers start out frozen, meaning their weights aren’t updated during training unless we unfreeze them. Later, we will unfreeze all the layers and use a range of learning rates to help adjust them slightly for our artwork classification.\nFastai recommends training the frozen pretrained model for a few epochs before training the full pretrained model. We’ll start with 3 epochs frozen using the learning rate we found before and then train the full model for 25 epochs. We can get an idea of how our error rates changes across training from here. Our losses along with our metrics will be useful in determining if we’ve fitted a decent model or whether we are underfitting or overfitting.\n\n\nCode\nlearn.fit_one_cycle(3, lr_steep.steep)\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.632305\n0.351879\n0.885514\n00:11\n\n\n1\n0.367901\n0.266535\n0.911215\n00:11\n\n\n2\n0.290731\n0.255560\n0.912383\n00:11\n\n\n\n\n\n\n\nCode\nlearn.unfreeze()\nlearn.lr_find()\n\n\n\n\n\nSuggestedLRs(valley=3.0199516913853586e-05)\n\n\n\n\n\n\n\nCode\nlearn.fit_one_cycle(30, 1e-5)\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.278328\n0.252081\n0.913551\n00:12\n\n\n1\n0.270599\n0.246448\n0.917056\n00:12\n\n\n2\n0.257108\n0.233751\n0.920561\n00:12\n\n\n3\n0.248420\n0.236578\n0.913551\n00:12\n\n\n4\n0.225075\n0.217247\n0.922897\n00:12\n\n\n5\n0.219640\n0.218755\n0.921729\n00:12\n\n\n6\n0.193035\n0.220623\n0.927570\n00:12\n\n\n7\n0.181702\n0.207903\n0.929907\n00:12\n\n\n8\n0.153848\n0.203974\n0.931075\n00:13\n\n\n9\n0.140883\n0.205168\n0.928738\n00:12\n\n\n10\n0.122441\n0.198469\n0.932243\n00:12\n\n\n11\n0.122553\n0.203679\n0.927570\n00:12\n\n\n12\n0.105032\n0.212182\n0.929907\n00:12\n\n\n13\n0.107883\n0.198044\n0.936916\n00:13\n\n\n14\n0.100362\n0.198456\n0.939252\n00:13\n\n\n15\n0.093048\n0.206936\n0.932243\n00:13\n\n\n16\n0.077934\n0.204801\n0.938084\n00:12\n\n\n17\n0.081075\n0.208896\n0.933411\n00:13\n\n\n18\n0.076961\n0.210113\n0.934579\n00:12\n\n\n19\n0.065377\n0.203140\n0.932243\n00:13\n\n\n20\n0.063294\n0.201389\n0.939252\n00:12\n\n\n21\n0.063553\n0.204729\n0.935748\n00:13\n\n\n22\n0.059901\n0.220824\n0.934579\n00:12\n\n\n23\n0.053123\n0.210733\n0.933411\n00:13\n\n\n24\n0.054386\n0.207903\n0.939252\n00:12\n\n\n25\n0.057231\n0.219750\n0.935748\n00:12\n\n\n26\n0.056672\n0.218769\n0.935748\n00:12\n\n\n27\n0.047327\n0.207138\n0.935748\n00:13\n\n\n28\n0.060546\n0.209229\n0.938084\n00:12\n\n\n29\n0.053616\n0.211565\n0.936916\n00:12"
  },
  {
    "objectID": "posts/projects/artwork_classifier/index.html#interpreting-the-loss-curves-further-training",
    "href": "posts/projects/artwork_classifier/index.html#interpreting-the-loss-curves-further-training",
    "title": "Classifying Artwork Types With Fastai",
    "section": "5.3 Interpreting the Loss Curves, Further Training?",
    "text": "5.3 Interpreting the Loss Curves, Further Training?\nAfter training our model, we will see how our training and validation losses have changed over the course of our iteration / epochs using loss curves. Loss curves won’t provide the entire story of our model but we’ll have a broad picture of how our model performs over the selected dataset and batch size.\n\n\nCode\nlearn.recorder.plot_loss()\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\n\n\nText(0, 0.5, 'Loss')\n\n\n\n\n\nInitially, our validation loss starts out lower than our training loss but our training loss quickly converges as our training progresses.\nWe should note that we reach a point where our validation loss is higher than our training loss. The former also does not seem to converge any more which leads us to an important question: are we overfitting?"
  },
  {
    "objectID": "posts/projects/artwork_classifier/index.html#overfitting",
    "href": "posts/projects/artwork_classifier/index.html#overfitting",
    "title": "Classifying Artwork Types With Fastai",
    "section": "5.4 Overfitting",
    "text": "5.4 Overfitting\nOverfitting occurs when we have trained for too long and the model begins to “memorize” the training data while failing to generalize well to new data.\nWhen we look at our losses, we might decide an increasing validation loss with a continually decreasing training loss means we are overfitting. However, this is not necessarily the case–one key takeaway from fastai is that we should be checking if our performance metric is getting worse to decide if the model is overfitting.\n\n\nCode\naccuracy_metric = L(learn.recorder.values).itemgot(2)\nprint(f'Highest accuracy during last run: {np.argmax(accuracy_metric)}')\nplt.xlabel('Accuracy')\nplt.ylabel('Epoch')\nplt.xticks(np.arange(0, len(accuracy_metric) + 1, 5))\nplt.plot(accuracy_metric);\n\n\nHighest accuracy during last run: 14\n\n\n\n\n\nOur highest accuracy is at epoch 14 and it doesn’t show clear signs of improvement with additional training. If we take into account both our validation loss and metric, then our model might be overfitting but it’s not clear. However, we have a few options here! We could introduce regularization, choose a deeper architecture or even rerun our model with a lower number of epochs and adjust from there. In this case, we will select a deeper architecture using discriminative learning rates. Using a deeper model, we might be able to learn the patterns of our data better.\nWe should keep in mind that our performance metric is what ultimately matters in practice.\nAs Jeremy Howard states:\n\n“In the end what matters is your accuracy, or more generally your chosen metrics, not the loss. The loss is just the function we’ve given the computer to help us to optimize.”\n“Remember, it’s not just that we’re looking for the validation loss to get worse, but the actual metrics. Your validation loss will first get worse during training because the model gets overconfident, and only later will get worse because it is incorrectly memorizing the data. We only care in practice about the latter issue. Remember, our loss function is just something that we use to allow our optimizer to have something it can differentiate and optimize; it’s not actually the thing we care about in practice.”\n\nTo really evaluate our model’s performance, we would run our model on a representative test data set that it has never seen before. This would help us get a good idea of our model’s practical performance.\n\n\nCode\n# Reinitialize our model to restart training\nlearn = vision_learner(dls, resnet101, metrics=accuracy)\n\n\n\n\nCode\nlr_steep = learn.lr_find(suggest_funcs=steep, show_plot=False)\n\nlearn.fit_one_cycle(3, lr_steep.steep)\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.630548\n0.262199\n0.907710\n00:14\n\n\n1\n0.352523\n0.220467\n0.919393\n00:14\n\n\n2\n0.275075\n0.213857\n0.920561\n00:14\n\n\n\n\n\n\n\nCode\nlearn.unfreeze()\nlearn.lr_find()\n\n\n\n\n\nSuggestedLRs(valley=1.737800812406931e-05)\n\n\n\n\n\n\n\nCode\nlearn.fit_one_cycle(10, lr_max=slice(1e-6, 1e-4))\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.271231\n0.216878\n0.915888\n00:17\n\n\n1\n0.233810\n0.186462\n0.928738\n00:17\n\n\n2\n0.212894\n0.168020\n0.928738\n00:17\n\n\n3\n0.175912\n0.168379\n0.927570\n00:17\n\n\n4\n0.156709\n0.168505\n0.933411\n00:17\n\n\n5\n0.136558\n0.161048\n0.948598\n00:17\n\n\n6\n0.124741\n0.157284\n0.936916\n00:17\n\n\n7\n0.105511\n0.157003\n0.943925\n00:18\n\n\n8\n0.105623\n0.155143\n0.947430\n00:17\n\n\n9\n0.108300\n0.154238\n0.945093\n00:18\n\n\n\n\n\nWe improved our accuracy up to around 94% by using a deeper model with discriminative learning rates. However, every choice has tradeoffs. Training a deeper model takes more time in general and in our low-risk context the increase in accuracy could be neglible. Let’s take a closer look at how our fine-tuned model is doing on our image set.\n\n\nCode\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\nCode\ninterp.print_classification_report()\n\n\n\n\n\n              precision    recall  f1-score   support\n\n    drawings       0.85      0.80      0.83       122\n   engraving       0.79      0.86      0.82        84\n iconography       0.97      1.00      0.99       231\n    painting       0.98      0.96      0.97       228\n   sculpture       0.99      0.99      0.99       191\n\n    accuracy                           0.95       856\n   macro avg       0.92      0.92      0.92       856\nweighted avg       0.95      0.95      0.95       856\n\n\n\nThe weighted F1-score is the the mean of all the class F1 scores while taking into account the number of occurrences in each class. The score has a range from 0 to 1. Our model achieved a weighted F1-score of 0.95. Not bad!\nIn production, we should take these results with a grain of salt since we haven’t done any true performance testing. But it’s fascinating that we can achieve such results with just a bit of conceptual understanding and a few lines of code!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cracking Data with Yang",
    "section": "",
    "text": "Classifying Artwork Types With Fastai\n\n\n\n\n\n\n\nproject\n\n\nmachine learning\n\n\ncomputer vision\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2023\n\n\nYang Chen\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Cracking Data is all about my love for experimenting with data. It’s a collection of articles which help explain awesome tools, concepts, and projects through the context of disciplines that I am passionate about like art and martial arts!\nWho am I? I’m a data science Master’s student who’s interested in AI, deep learning, and explainable data science. I aim to keep my work fun and informative so others might be inspired to share their own experiments."
  }
]